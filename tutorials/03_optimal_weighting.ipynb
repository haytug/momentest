{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial 3: Optimal Weighting (Two-Step Estimation)\n",
                "\n",
                "This tutorial explains **optimal weighting** in GMM/SMM and demonstrates the **two-step estimation** procedure.\n",
                "\n",
                "## What You'll Learn\n",
                "\n",
                "1. Why the weighting matrix matters\n",
                "2. Identity vs optimal weighting\n",
                "3. The two-step estimation procedure\n",
                "4. Efficiency gains from optimal weighting\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Completed Tutorials 1-2\n",
                "- Basic understanding of variance and efficiency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from momentest import (\n",
                "    gmm_estimate,\n",
                "    smm_estimate,\n",
                "    linear_iv,\n",
                "    table_estimates,\n",
                "    confidence_interval,\n",
                "    load_econ381,\n",
                ")\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The GMM/SMM Objective Function\n",
                "\n",
                "Recall the GMM/SMM objective:\n",
                "\n",
                "$$Q(\\theta) = \\bar{g}(\\theta)' W \\bar{g}(\\theta)$$\n",
                "\n",
                "where:\n",
                "- $\\bar{g}(\\theta)$ = sample/simulated moments (k × 1)\n",
                "- $W$ = weighting matrix (k × k)\n",
                "\n",
                "### Why Does W Matter?\n",
                "\n",
                "The weighting matrix determines:\n",
                "1. **Which moments get more weight** in the objective\n",
                "2. **The efficiency** of the estimator (variance of $\\hat{\\theta}$)\n",
                "\n",
                "Different W → Same point estimate (asymptotically) but different standard errors!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Identity Weighting\n",
                "\n",
                "The simplest choice is $W = I$ (identity matrix):\n",
                "\n",
                "$$Q(\\theta) = \\bar{g}(\\theta)' I \\bar{g}(\\theta) = \\sum_{j=1}^k \\bar{g}_j(\\theta)^2$$\n",
                "\n",
                "This treats all moments equally. It's:\n",
                "- **Simple**: No need to estimate W\n",
                "- **Consistent**: Still gives correct point estimates\n",
                "- **Inefficient**: Doesn't account for moment correlations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Optimal Weighting\n",
                "\n",
                "Hansen (1982) showed that the **efficient** choice is:\n",
                "\n",
                "$$W^* = S^{-1}$$\n",
                "\n",
                "where $S = Var(\\bar{g}(\\theta_0))$ is the covariance matrix of the moment conditions.\n",
                "\n",
                "### Intuition\n",
                "\n",
                "- Moments with **high variance** get **less weight**\n",
                "- Moments with **low variance** get **more weight**\n",
                "- Correlated moments are properly accounted for\n",
                "\n",
                "This is like **GLS** (Generalized Least Squares) for moment conditions!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Two-Step Procedure\n",
                "\n",
                "The problem: We need $S$ to compute $W^*$, but $S$ depends on $\\theta_0$ (unknown).\n",
                "\n",
                "**Solution: Two-step estimation**\n",
                "\n",
                "1. **Step 1**: Estimate with $W = I$ → get $\\hat{\\theta}_1$\n",
                "2. **Compute**: $\\hat{S} = \\hat{Var}(\\bar{g}(\\hat{\\theta}_1))$\n",
                "3. **Step 2**: Re-estimate with $W = \\hat{S}^{-1}$ → get $\\hat{\\theta}_2$ (efficient)\n",
                "\n",
                "This is what `weighting=\"optimal\"` does automatically!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Example: Linear IV Model\n",
                "\n",
                "Let's compare identity vs optimal weighting:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate data\n",
                "dgp = linear_iv(n=500, seed=42, beta0=1.0, beta1=2.0, rho=0.5)\n",
                "\n",
                "# Add extra instruments for overidentification\n",
                "dgp.data['Z2'] = dgp.data['Z']**2\n",
                "dgp.data['Z3'] = dgp.data['Z']**3\n",
                "\n",
                "def moment_func(data, theta):\n",
                "    \"\"\"4 moments, 2 parameters (overidentified).\"\"\"\n",
                "    beta0, beta1 = theta\n",
                "    residual = data['Y'] - beta0 - beta1 * data['X']\n",
                "    \n",
                "    return np.column_stack([\n",
                "        residual,\n",
                "        residual * data['Z'],\n",
                "        residual * data['Z2'],\n",
                "        residual * data['Z3'],\n",
                "    ])\n",
                "\n",
                "print(f\"True parameters: β₀={dgp.true_theta[0]}, β₁={dgp.true_theta[1]}\")\n",
                "print(f\"Model: k=4 moments, p=2 parameters (overidentified)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identity weighting (one-step)\n",
                "result_identity = gmm_estimate(\n",
                "    data=dgp.data,\n",
                "    moment_func=moment_func,\n",
                "    bounds=[(-10, 10), (-10, 10)],\n",
                "    k=4,\n",
                "    weighting=\"identity\",\n",
                ")\n",
                "\n",
                "# Optimal weighting (two-step)\n",
                "result_optimal = gmm_estimate(\n",
                "    data=dgp.data,\n",
                "    moment_func=moment_func,\n",
                "    bounds=[(-10, 10), (-10, 10)],\n",
                "    k=4,\n",
                "    weighting=\"optimal\",\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"COMPARISON: Identity vs Optimal Weighting\")\n",
                "print(\"=\"*70)\n",
                "print(f\"{'Weighting':<15} {'β₀':>10} {'SE(β₀)':>10} {'β₁':>10} {'SE(β₁)':>10}\")\n",
                "print(\"-\"*55)\n",
                "print(f\"{'Identity':<15} {result_identity.theta[0]:>10.4f} {result_identity.se[0]:>10.4f} \"\n",
                "      f\"{result_identity.theta[1]:>10.4f} {result_identity.se[1]:>10.4f}\")\n",
                "print(f\"{'Optimal':<15} {result_optimal.theta[0]:>10.4f} {result_optimal.se[0]:>10.4f} \"\n",
                "      f\"{result_optimal.theta[1]:>10.4f} {result_optimal.se[1]:>10.4f}\")\n",
                "print(f\"{'True':<15} {dgp.true_theta[0]:>10.4f} {'-':>10} {dgp.true_theta[1]:>10.4f} {'-':>10}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Efficiency gain\n",
                "se_ratio_b0 = result_identity.se[0] / result_optimal.se[0]\n",
                "se_ratio_b1 = result_identity.se[1] / result_optimal.se[1]\n",
                "\n",
                "print(f\"\\nEfficiency gain (SE ratio):\")\n",
                "print(f\"  β₀: {se_ratio_b0:.2f}x (optimal is {se_ratio_b0:.0%} as efficient)\")\n",
                "print(f\"  β₁: {se_ratio_b1:.2f}x (optimal is {se_ratio_b1:.0%} as efficient)\")\n",
                "print(f\"\\nOptimal weighting gives LOWER standard errors!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Monte Carlo: Efficiency Comparison\n",
                "\n",
                "Let's run a Monte Carlo simulation to see the efficiency gain more clearly:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monte Carlo simulation\n",
                "n_mc = 100\n",
                "estimates_identity = []\n",
                "estimates_optimal = []\n",
                "\n",
                "print(\"Running Monte Carlo simulation...\")\n",
                "for i in range(n_mc):\n",
                "    # Generate new data\n",
                "    dgp_mc = linear_iv(n=500, seed=i, beta0=1.0, beta1=2.0, rho=0.5)\n",
                "    dgp_mc.data['Z2'] = dgp_mc.data['Z']**2\n",
                "    dgp_mc.data['Z3'] = dgp_mc.data['Z']**3\n",
                "    \n",
                "    # Identity weighting\n",
                "    try:\n",
                "        res_id = gmm_estimate(\n",
                "            data=dgp_mc.data, moment_func=moment_func,\n",
                "            bounds=[(-10, 10), (-10, 10)], k=4, weighting=\"identity\",\n",
                "        )\n",
                "        estimates_identity.append(res_id.theta)\n",
                "    except:\n",
                "        pass\n",
                "    \n",
                "    # Optimal weighting\n",
                "    try:\n",
                "        res_opt = gmm_estimate(\n",
                "            data=dgp_mc.data, moment_func=moment_func,\n",
                "            bounds=[(-10, 10), (-10, 10)], k=4, weighting=\"optimal\",\n",
                "        )\n",
                "        estimates_optimal.append(res_opt.theta)\n",
                "    except:\n",
                "        pass\n",
                "    \n",
                "    if (i + 1) % 20 == 0:\n",
                "        print(f\"  Completed {i+1}/{n_mc}\")\n",
                "\n",
                "estimates_identity = np.array(estimates_identity)\n",
                "estimates_optimal = np.array(estimates_optimal)\n",
                "\n",
                "print(f\"\\nCompleted {len(estimates_identity)} identity, {len(estimates_optimal)} optimal\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare distributions\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "for i, (ax, param_name, true_val) in enumerate(zip(axes, ['β₀', 'β₁'], [1.0, 2.0])):\n",
                "    ax.hist(estimates_identity[:, i], bins=20, alpha=0.5, label='Identity', density=True)\n",
                "    ax.hist(estimates_optimal[:, i], bins=20, alpha=0.5, label='Optimal', density=True)\n",
                "    ax.axvline(true_val, color='red', linestyle='--', linewidth=2, label='True')\n",
                "    ax.set_xlabel(param_name)\n",
                "    ax.set_ylabel('Density')\n",
                "    ax.set_title(f'Distribution of {param_name} Estimates')\n",
                "    ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Summary statistics\n",
                "print(\"\\nMonte Carlo Results:\")\n",
                "print(f\"{'Weighting':<12} {'Mean(β₁)':>10} {'Std(β₁)':>10} {'RMSE(β₁)':>10}\")\n",
                "print(\"-\"*45)\n",
                "bias_id = estimates_identity[:, 1].mean() - 2.0\n",
                "std_id = estimates_identity[:, 1].std()\n",
                "rmse_id = np.sqrt(bias_id**2 + std_id**2)\n",
                "print(f\"{'Identity':<12} {estimates_identity[:, 1].mean():>10.4f} {std_id:>10.4f} {rmse_id:>10.4f}\")\n",
                "\n",
                "bias_opt = estimates_optimal[:, 1].mean() - 2.0\n",
                "std_opt = estimates_optimal[:, 1].std()\n",
                "rmse_opt = np.sqrt(bias_opt**2 + std_opt**2)\n",
                "print(f\"{'Optimal':<12} {estimates_optimal[:, 1].mean():>10.4f} {std_opt:>10.4f} {rmse_opt:>10.4f}\")\n",
                "print(f\"{'True':<12} {2.0:>10.4f}\")\n",
                "\n",
                "print(f\"\\nEfficiency gain: Optimal has {std_id/std_opt:.1%} lower std dev\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. When Does Optimal Weighting Help Most?\n",
                "\n",
                "Optimal weighting helps most when:\n",
                "\n",
                "1. **Moments have different variances**: High-variance moments get downweighted\n",
                "2. **Moments are correlated**: Correlations are properly accounted for\n",
                "3. **Model is overidentified**: More moments → more room for efficiency gains\n",
                "\n",
                "### When It Doesn't Matter\n",
                "\n",
                "- **Exactly identified** (k = p): All weighting matrices give the same estimate\n",
                "- **Homoskedastic, uncorrelated moments**: Identity is already optimal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exactly identified case (k = p = 2)\n",
                "def moment_func_exact(data, theta):\n",
                "    \"\"\"2 moments, 2 parameters (exactly identified).\"\"\"\n",
                "    beta0, beta1 = theta\n",
                "    residual = data['Y'] - beta0 - beta1 * data['X']\n",
                "    return np.column_stack([residual, residual * data['Z']])\n",
                "\n",
                "dgp_exact = linear_iv(n=500, seed=42)\n",
                "\n",
                "res_exact_id = gmm_estimate(\n",
                "    data=dgp_exact.data, moment_func=moment_func_exact,\n",
                "    bounds=[(-10, 10), (-10, 10)], k=2, weighting=\"identity\",\n",
                ")\n",
                "\n",
                "res_exact_opt = gmm_estimate(\n",
                "    data=dgp_exact.data, moment_func=moment_func_exact,\n",
                "    bounds=[(-10, 10), (-10, 10)], k=2, weighting=\"optimal\",\n",
                ")\n",
                "\n",
                "print(\"Exactly Identified (k=p=2):\")\n",
                "print(f\"  Identity: β₁ = {res_exact_id.theta[1]:.4f}\")\n",
                "print(f\"  Optimal:  β₁ = {res_exact_opt.theta[1]:.4f}\")\n",
                "print(f\"\\nSame estimate! Weighting doesn't matter when exactly identified.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. The Weighting Matrix in Detail\n",
                "\n",
                "Let's look at what the optimal weighting matrix looks like:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the moment covariance at the estimate\n",
                "from momentest import GMMEngine\n",
                "\n",
                "engine = GMMEngine(\n",
                "    data=dgp.data,\n",
                "    k=4,\n",
                "    p=2,\n",
                "    moment_func=moment_func,\n",
                ")\n",
                "\n",
                "_, S = engine.moments(result_optimal.theta)\n",
                "\n",
                "print(\"Moment Covariance Matrix S:\")\n",
                "print(np.round(S, 4))\n",
                "\n",
                "print(\"\\nOptimal Weighting Matrix W = S⁻¹:\")\n",
                "W_opt = np.linalg.inv(S)\n",
                "print(np.round(W_opt, 4))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the weighting matrix\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Covariance matrix\n",
                "im1 = axes[0].imshow(S, cmap='RdBu_r', aspect='auto')\n",
                "axes[0].set_title('Moment Covariance S')\n",
                "axes[0].set_xticks(range(4))\n",
                "axes[0].set_yticks(range(4))\n",
                "axes[0].set_xticklabels(['g₁', 'g₂', 'g₃', 'g₄'])\n",
                "axes[0].set_yticklabels(['g₁', 'g₂', 'g₃', 'g₄'])\n",
                "plt.colorbar(im1, ax=axes[0])\n",
                "\n",
                "# Weighting matrix\n",
                "im2 = axes[1].imshow(W_opt, cmap='RdBu_r', aspect='auto')\n",
                "axes[1].set_title('Optimal Weighting W = S⁻¹')\n",
                "axes[1].set_xticks(range(4))\n",
                "axes[1].set_yticks(range(4))\n",
                "axes[1].set_xticklabels(['g₁', 'g₂', 'g₃', 'g₄'])\n",
                "axes[1].set_yticklabels(['g₁', 'g₂', 'g₃', 'g₄'])\n",
                "plt.colorbar(im2, ax=axes[1])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Exercises\n",
                "\n",
                "### Exercise 1: Vary Overidentification\n",
                "Compare efficiency gains with k=3, k=4, k=5 moments. Does more overidentification help?\n",
                "\n",
                "### Exercise 2: Heteroskedasticity\n",
                "Generate data with heteroskedastic errors. How much does optimal weighting help?\n",
                "\n",
                "### Exercise 3: SMM Weighting\n",
                "Repeat the comparison for SMM (Tutorial 2 example). Is the efficiency gain similar?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1 starter code\n",
                "print(\"Efficiency gain by number of moments:\")\n",
                "print(f\"{'k':>5} {'SE(β₁) Identity':>18} {'SE(β₁) Optimal':>18} {'Ratio':>10}\")\n",
                "print(\"-\"*55)\n",
                "\n",
                "for k in [2, 3, 4]:\n",
                "    # Define moment function with k moments\n",
                "    def make_moment_func(k):\n",
                "        def mf(data, theta):\n",
                "            beta0, beta1 = theta\n",
                "            residual = data['Y'] - beta0 - beta1 * data['X']\n",
                "            moments = [residual]\n",
                "            if k >= 2:\n",
                "                moments.append(residual * data['Z'])\n",
                "            if k >= 3:\n",
                "                moments.append(residual * data['Z']**2)\n",
                "            if k >= 4:\n",
                "                moments.append(residual * data['Z']**3)\n",
                "            return np.column_stack(moments)\n",
                "        return mf\n",
                "    \n",
                "    mf = make_moment_func(k)\n",
                "    \n",
                "    res_id = gmm_estimate(data=dgp.data, moment_func=mf, bounds=[(-10, 10), (-10, 10)], k=k, weighting=\"identity\")\n",
                "    res_opt = gmm_estimate(data=dgp.data, moment_func=mf, bounds=[(-10, 10), (-10, 10)], k=k, weighting=\"optimal\")\n",
                "    \n",
                "    ratio = res_id.se[1] / res_opt.se[1] if res_opt.se[1] > 0 else np.nan\n",
                "    print(f\"{k:>5} {res_id.se[1]:>18.4f} {res_opt.se[1]:>18.4f} {ratio:>10.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this tutorial, you learned:\n",
                "\n",
                "1. **Weighting matrix**: Determines which moments get more weight\n",
                "2. **Identity weighting**: Simple but inefficient\n",
                "3. **Optimal weighting**: $W = S^{-1}$ is efficient (Hansen 1982)\n",
                "4. **Two-step procedure**: First estimate with identity, then re-estimate with optimal\n",
                "5. **Efficiency gains**: Optimal weighting reduces standard errors\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "- Use `weighting=\"optimal\"` for efficient estimation\n",
                "- Efficiency gains are larger with more overidentification\n",
                "- For exactly identified models, weighting doesn't matter\n",
                "- `momentest` handles two-step automatically\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- **Tutorial 4**: Bootstrap inference\n",
                "- **Tutorial 5**: Diagnostics and visualization"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}