{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial 7: Real Data Applications\n",
                "\n",
                "This tutorial demonstrates **GMM and SMM estimation with real datasets**. We'll work through two complete applications:\n",
                "\n",
                "1. **GMM**: Labor supply estimation using PSID data (Mroz 1987)\n",
                "2. **SMM**: Income dynamics estimation using consumption data\n",
                "\n",
                "## What You'll Learn\n",
                "\n",
                "1. How to apply GMM to real microeconomic data\n",
                "2. Instrumental variables estimation for labor supply\n",
                "3. How to use SMM for models with latent dynamics\n",
                "4. Best practices for real-world estimation\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Completed Tutorials 1-5\n",
                "- Understanding of IV estimation\n",
                "- Basic knowledge of labor economics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.stats as sts\n",
                "\n",
                "from momentest import (\n",
                "    gmm_estimate,\n",
                "    smm_estimate,\n",
                "    load_labor_supply,\n",
                "    load_consumption,\n",
                "    list_datasets,\n",
                "    j_test,\n",
                "    table_estimates,\n",
                "    confidence_interval,\n",
                "    plot_moment_comparison,\n",
                ")\n",
                "\n",
                "np.random.seed(42)\n",
                "np.set_printoptions(precision=4, suppress=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Available Datasets\n",
                "\n",
                "Let's see what real datasets are available in `momentest`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Available datasets:\")\n",
                "for name in list_datasets():\n",
                "    print(f\"  - {name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: GMM with Labor Supply Data\n",
                "\n",
                "## The Mroz (1987) Dataset\n",
                "\n",
                "This classic dataset from the Panel Study of Income Dynamics (PSID) contains labor supply data for 753 married women in 1976. It's widely used for:\n",
                "\n",
                "- Labor supply estimation (wage elasticity)\n",
                "- Sample selection models (Heckman correction)\n",
                "- IV/GMM examples in econometrics courses\n",
                "\n",
                "### The Economic Question\n",
                "\n",
                "**How responsive is labor supply to wages?**\n",
                "\n",
                "The wage elasticity of labor supply (γ) tells us how much hours worked change when wages change:\n",
                "\n",
                "$\\gamma = \\frac{\\partial \\ln(hours)}{\\partial \\ln(wage)}$\n",
                "\n",
                "This is crucial for:\n",
                "- Tax policy (how do taxes affect work incentives?)\n",
                "- Welfare programs (how do benefits affect labor supply?)\n",
                "- Gender wage gap analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the labor supply dataset\n",
                "labor_data = load_labor_supply()\n",
                "\n",
                "# Print detailed information\n",
                "labor_data.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explore the data\n",
                "print(f\"\\nSample size: {labor_data.n} working women\")\n",
                "print(\"\\nVariable summary:\")\n",
                "print(\"-\" * 60)\n",
                "for var in ['log_hours', 'log_wage', 'age', 'education', 'experience']:\n",
                "    x = labor_data.data[var]\n",
                "    print(f\"{var:15s}: mean={x.mean():8.2f}, std={x.std():8.2f}, min={x.min():8.2f}, max={x.max():8.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the data\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
                "\n",
                "# Hours distribution\n",
                "ax = axes[0, 0]\n",
                "ax.hist(labor_data.data['hours'], bins=30, edgecolor='black', alpha=0.7)\n",
                "ax.set_xlabel('Annual Hours Worked')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.set_title('Distribution of Hours Worked')\n",
                "\n",
                "# Wage distribution\n",
                "ax = axes[0, 1]\n",
                "ax.hist(labor_data.data['wage'], bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
                "ax.set_xlabel('Hourly Wage ($)')\n",
                "ax.set_ylabel('Frequency')\n",
                "ax.set_title('Distribution of Wages')\n",
                "\n",
                "# Hours vs Wage scatter\n",
                "ax = axes[1, 0]\n",
                "ax.scatter(labor_data.data['log_wage'], labor_data.data['log_hours'], alpha=0.5, s=20)\n",
                "ax.set_xlabel('Log Wage')\n",
                "ax.set_ylabel('Log Hours')\n",
                "ax.set_title('Log Hours vs Log Wage')\n",
                "\n",
                "# Education vs Wage\n",
                "ax = axes[1, 1]\n",
                "ax.scatter(labor_data.data['education'], labor_data.data['log_wage'], alpha=0.5, s=20, color='green')\n",
                "ax.set_xlabel('Years of Education')\n",
                "ax.set_ylabel('Log Wage')\n",
                "ax.set_title('Log Wage vs Education')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Endogeneity Problem\n",
                "\n",
                "### Why OLS Fails\n",
                "\n",
                "Consider the labor supply equation:\n",
                "\n",
                "$\\ln(hours_i) = \\alpha + \\gamma \\ln(wage_i) + \\beta' X_i + \\varepsilon_i$\n",
                "\n",
                "**Problem**: Wages are **endogenous**!\n",
                "\n",
                "- Unobserved ability affects both wages and hours\n",
                "- High-ability workers earn more AND may work more (or less!)\n",
                "- $Cov(\\ln(wage), \\varepsilon) \\neq 0$\n",
                "\n",
                "**Result**: OLS estimates of γ are biased."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OLS estimation (biased)\n",
                "Y = labor_data.data['log_hours']\n",
                "X_ols = np.column_stack([\n",
                "    labor_data.data['constant'],\n",
                "    labor_data.data['log_wage'],\n",
                "    labor_data.data['education'],\n",
                "    labor_data.data['experience'],\n",
                "    labor_data.data['experience_sq'] / 100,  # Scale for numerical stability\n",
                "])\n",
                "\n",
                "beta_ols = np.linalg.lstsq(X_ols, Y, rcond=None)[0]\n",
                "\n",
                "print(\"OLS Estimates (potentially biased):\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"{'Parameter':<20} {'Estimate':>12}\")\n",
                "print(\"-\" * 35)\n",
                "print(f\"{'Constant':<20} {beta_ols[0]:>12.4f}\")\n",
                "print(f\"{'γ (wage elasticity)':<20} {beta_ols[1]:>12.4f}\")\n",
                "print(f\"{'Education':<20} {beta_ols[2]:>12.4f}\")\n",
                "print(f\"{'Experience':<20} {beta_ols[3]:>12.4f}\")\n",
                "print(f\"{'Experience²/100':<20} {beta_ols[4]:>12.4f}\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\\n⚠️  The wage elasticity may be biased due to endogeneity!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GMM with Instrumental Variables\n",
                "\n",
                "### The Solution: Use Instruments\n",
                "\n",
                "We need instruments $Z$ that:\n",
                "1. **Relevance**: $Cov(Z, \\ln(wage)) \\neq 0$ (correlated with wage)\n",
                "2. **Exclusion**: $Cov(Z, \\varepsilon) = 0$ (uncorrelated with labor supply error)\n",
                "\n",
                "### Classic Instruments: Husband's Characteristics\n",
                "\n",
                "- **Husband's education** (`heducation`)\n",
                "- **Husband's age** (`hage`)\n",
                "\n",
                "**Why valid?**\n",
                "- Assortative mating: High-education husbands tend to have high-education wives → correlated with wife's wage\n",
                "- Exclusion: Husband's education shouldn't directly affect wife's hours (conditional on her wage)\n",
                "\n",
                "### GMM Moment Conditions\n",
                "\n",
                "The residual $\\varepsilon_i = \\ln(hours_i) - \\alpha - \\gamma \\ln(wage_i) - \\beta' X_i$ should be orthogonal to instruments:\n",
                "\n",
                "1. $E[\\varepsilon] = 0$\n",
                "2. $E[\\varepsilon \\cdot heducation] = 0$ (IV for wage)\n",
                "3. $E[\\varepsilon \\cdot education] = 0$ (exogenous)\n",
                "4. $E[\\varepsilon \\cdot experience] = 0$ (exogenous)\n",
                "5. $E[\\varepsilon \\cdot experience^2] = 0$ (exogenous)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check instrument relevance: First stage regression\n",
                "# Regress log_wage on instruments\n",
                "Z_first = np.column_stack([\n",
                "    labor_data.data['constant'],\n",
                "    labor_data.data['heducation'],\n",
                "    labor_data.data['education'],\n",
                "    labor_data.data['experience'],\n",
                "    labor_data.data['experience_sq'] / 100,\n",
                "])\n",
                "\n",
                "gamma_first = np.linalg.lstsq(Z_first, labor_data.data['log_wage'], rcond=None)[0]\n",
                "fitted_wage = Z_first @ gamma_first\n",
                "residuals_first = labor_data.data['log_wage'] - fitted_wage\n",
                "r_squared = 1 - np.var(residuals_first) / np.var(labor_data.data['log_wage'])\n",
                "\n",
                "print(\"First Stage: log_wage on instruments\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Coefficient on heducation: {gamma_first[1]:.4f}\")\n",
                "print(f\"R-squared: {r_squared:.4f}\")\n",
                "print(\"\\n✓ Husband's education is correlated with wife's wage (relevance)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def labor_supply_moments(data, theta):\n",
                "    \"\"\"\n",
                "    GMM moment conditions for labor supply estimation.\n",
                "    \n",
                "    Model: ln(hours) = α + γ*ln(wage) + β₁*edu + β₂*exp + β₃*exp² + ε\n",
                "    \n",
                "    Args:\n",
                "        data: Dictionary with labor supply variables\n",
                "        theta: [alpha, gamma, beta_edu, beta_exp, beta_exp2]\n",
                "    \n",
                "    Returns:\n",
                "        Moment conditions of shape (n, k)\n",
                "    \"\"\"\n",
                "    alpha, gamma, beta_edu, beta_exp, beta_exp2 = theta\n",
                "    \n",
                "    # Compute residual\n",
                "    residual = (data['log_hours'] \n",
                "                - alpha \n",
                "                - gamma * data['log_wage']\n",
                "                - beta_edu * data['education']\n",
                "                - beta_exp * data['experience']\n",
                "                - beta_exp2 * data['experience_sq'] / 100)\n",
                "    \n",
                "    # Moment conditions: E[ε * Z] = 0\n",
                "    moments = np.column_stack([\n",
                "        residual,                              # E[ε] = 0\n",
                "        residual * data['heducation'],         # E[ε * hedu] = 0 (IV)\n",
                "        residual * data['education'],          # E[ε * edu] = 0\n",
                "        residual * data['experience'],         # E[ε * exp] = 0\n",
                "        residual * data['experience_sq'] / 100, # E[ε * exp²] = 0\n",
                "    ])\n",
                "    \n",
                "    return moments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GMM estimation - just identified (5 moments, 5 parameters)\n",
                "result_labor = gmm_estimate(\n",
                "    data=labor_data.data,\n",
                "    moment_func=labor_supply_moments,\n",
                "    bounds=[\n",
                "        (0, 10),      # alpha (constant)\n",
                "        (-2, 2),      # gamma (wage elasticity)\n",
                "        (-0.5, 0.5),  # beta_edu\n",
                "        (-0.5, 0.5),  # beta_exp\n",
                "        (-0.1, 0.1),  # beta_exp2\n",
                "    ],\n",
                "    k=5,\n",
                "    weighting=\"optimal\",\n",
                "    n_global=200,\n",
                "    seed=42,\n",
                ")\n",
                "\n",
                "print(result_labor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare OLS vs GMM\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"COMPARISON: OLS vs GMM (IV)\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"{'Parameter':<20} {'OLS':>12} {'GMM (IV)':>12} {'SE':>12}\")\n",
                "print(\"-\" * 60)\n",
                "print(f\"{'Constant':<20} {beta_ols[0]:>12.4f} {result_labor.theta[0]:>12.4f} {result_labor.se[0]:>12.4f}\")\n",
                "print(f\"{'γ (wage elasticity)':<20} {beta_ols[1]:>12.4f} {result_labor.theta[1]:>12.4f} {result_labor.se[1]:>12.4f}\")\n",
                "print(f\"{'Education':<20} {beta_ols[2]:>12.4f} {result_labor.theta[2]:>12.4f} {result_labor.se[2]:>12.4f}\")\n",
                "print(f\"{'Experience':<20} {beta_ols[3]:>12.4f} {result_labor.theta[3]:>12.4f} {result_labor.se[3]:>12.4f}\")\n",
                "print(f\"{'Experience²/100':<20} {beta_ols[4]:>12.4f} {result_labor.theta[4]:>12.4f} {result_labor.se[4]:>12.4f}\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Formatted results table\n",
                "ci_lower, ci_upper = confidence_interval(result_labor.theta, result_labor.se)\n",
                "\n",
                "print(table_estimates(\n",
                "    theta=result_labor.theta,\n",
                "    se=result_labor.se,\n",
                "    param_names=[\"α (constant)\", \"γ (wage elasticity)\", \"β_edu\", \"β_exp\", \"β_exp²\"],\n",
                "    ci_lower=ci_lower,\n",
                "    ci_upper=ci_upper,\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation\n",
                "\n",
                "The **wage elasticity** γ tells us:\n",
                "\n",
                "- A 1% increase in wages leads to approximately γ% change in hours worked\n",
                "- Positive γ: Higher wages → more hours (substitution effect dominates)\n",
                "- Negative γ: Higher wages → fewer hours (income effect dominates)\n",
                "\n",
                "**Typical findings in the literature:**\n",
                "- Women's labor supply elasticity: 0.1 to 0.5\n",
                "- Men's labor supply elasticity: ~0 (inelastic)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Overidentification Test\n",
                "\n",
                "Let's add husband's age as an additional instrument to test overidentifying restrictions:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def labor_supply_moments_overid(data, theta):\n",
                "    \"\"\"\n",
                "    Overidentified GMM: 6 moments, 5 parameters.\n",
                "    Adds husband's age as additional instrument.\n",
                "    \"\"\"\n",
                "    alpha, gamma, beta_edu, beta_exp, beta_exp2 = theta\n",
                "    \n",
                "    residual = (data['log_hours'] \n",
                "                - alpha \n",
                "                - gamma * data['log_wage']\n",
                "                - beta_edu * data['education']\n",
                "                - beta_exp * data['experience']\n",
                "                - beta_exp2 * data['experience_sq'] / 100)\n",
                "    \n",
                "    moments = np.column_stack([\n",
                "        residual,                              # E[ε] = 0\n",
                "        residual * data['heducation'],         # E[ε * hedu] = 0 (IV)\n",
                "        residual * data['hage'],               # E[ε * hage] = 0 (additional IV)\n",
                "        residual * data['education'],          # E[ε * edu] = 0\n",
                "        residual * data['experience'],         # E[ε * exp] = 0\n",
                "        residual * data['experience_sq'] / 100, # E[ε * exp²] = 0\n",
                "    ])\n",
                "    \n",
                "    return moments\n",
                "\n",
                "# Estimate overidentified model\n",
                "result_labor_overid = gmm_estimate(\n",
                "    data=labor_data.data,\n",
                "    moment_func=labor_supply_moments_overid,\n",
                "    bounds=[\n",
                "        (0, 10),      # alpha\n",
                "        (-2, 2),      # gamma\n",
                "        (-0.5, 0.5),  # beta_edu\n",
                "        (-0.5, 0.5),  # beta_exp\n",
                "        (-0.1, 0.1),  # beta_exp2\n",
                "    ],\n",
                "    k=6,  # Now 6 moments\n",
                "    weighting=\"optimal\",\n",
                "    n_global=200,\n",
                "    seed=42,\n",
                ")\n",
                "\n",
                "print(f\"Overidentified estimates:\")\n",
                "print(f\"  γ (wage elasticity) = {result_labor_overid.theta[1]:.4f} (SE: {result_labor_overid.se[1]:.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# J-test for overidentifying restrictions\n",
                "j_result = j_test(\n",
                "    objective=result_labor_overid.objective,\n",
                "    n=labor_data.n,\n",
                "    k=6,  # 6 moments\n",
                "    p=5,  # 5 parameters\n",
                ")\n",
                "\n",
                "print(j_result)\n",
                "print(\"\\nInterpretation:\")\n",
                "if j_result.p_value > 0.05:\n",
                "    print(\"  ✓ Fail to reject H₀: Instruments appear valid\")\n",
                "else:\n",
                "    print(\"  ⚠️ Reject H₀: At least one instrument may be invalid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Robustness: Comparing Estimates\n",
                "\n",
                "Let's compare our just-identified and overidentified estimates:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare estimates\n",
                "print(\"\\nComparison of GMM Estimates:\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"{'Specification':<25} {'γ (wage elast)':>15} {'SE':>12}\")\n",
                "print(\"-\" * 55)\n",
                "print(f\"{'Just-identified (k=5)':<25} {result_labor.theta[1]:>15.4f} {result_labor.se[1]:>12.4f}\")\n",
                "print(f\"{'Overidentified (k=6)':<25} {result_labor_overid.theta[1]:>15.4f} {result_labor_overid.se[1]:>12.4f}\")\n",
                "print(\"=\" * 70)\n",
                "print(\"\\nNote: For bootstrap inference, see the bootstrap() function in momentest.\")\n",
                "print(\"Bootstrap is especially useful for complex models where asymptotic SE may be unreliable.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: SMM for Income Dynamics\n",
                "\n",
                "Now let's use **Simulated Method of Moments (SMM)** for a model where analytical moments are difficult to compute.\n",
                "\n",
                "## The Model: AR(1) Income Process with Measurement Error\n",
                "\n",
                "Many economic models assume income follows an AR(1) process:\n",
                "\n",
                "$y_t^* = \\rho y_{t-1}^* + \\sigma_\\eta \\eta_t, \\quad \\eta_t \\sim N(0, 1)$\n",
                "\n",
                "But we observe income with measurement error:\n",
                "\n",
                "$y_t = y_t^* + \\sigma_\\varepsilon \\varepsilon_t, \\quad \\varepsilon_t \\sim N(0, 1)$\n",
                "\n",
                "**Parameters to estimate:**\n",
                "- $\\rho$: Persistence of income shocks\n",
                "- $\\sigma_\\eta$: Standard deviation of permanent shocks\n",
                "- $\\sigma_\\varepsilon$: Standard deviation of measurement error\n",
                "\n",
                "**Why SMM?**\n",
                "- The measurement error makes analytical moments complex\n",
                "- SMM lets us simulate the model and match moments directly"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using Consumption Data\n",
                "\n",
                "We'll use the consumption growth data to estimate income dynamics. The idea:\n",
                "- Consumption growth reflects underlying income shocks\n",
                "- We can match moments of consumption growth to identify income process parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load consumption data\n",
                "cons_data = load_consumption()\n",
                "cons_data.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract consumption growth\n",
                "c_growth = cons_data.data['c_growth']\n",
                "c_growth_lag1 = cons_data.data['c_growth_lag1']\n",
                "\n",
                "print(f\"Sample size: {len(c_growth)} quarters\")\n",
                "print(f\"\\nConsumption growth statistics:\")\n",
                "print(f\"  Mean: {c_growth.mean():.4f} ({(c_growth.mean()-1)*100:.2f}% per quarter)\")\n",
                "print(f\"  Std:  {c_growth.std():.4f}\")\n",
                "print(f\"  Autocorrelation: {np.corrcoef(c_growth[1:], c_growth[:-1])[0,1]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize consumption growth\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Time series\n",
                "ax = axes[0]\n",
                "ax.plot(c_growth, linewidth=0.8)\n",
                "ax.axhline(1.0, color='red', linestyle='--', alpha=0.5)\n",
                "ax.set_xlabel('Quarter')\n",
                "ax.set_ylabel('Consumption Growth (C_t / C_{t-1})')\n",
                "ax.set_title('U.S. Consumption Growth (1947-2025)')\n",
                "\n",
                "# Distribution\n",
                "ax = axes[1]\n",
                "ax.hist(c_growth, bins=50, density=True, edgecolor='black', alpha=0.7)\n",
                "ax.axvline(c_growth.mean(), color='red', linestyle='--', label=f'Mean: {c_growth.mean():.4f}')\n",
                "ax.set_xlabel('Consumption Growth')\n",
                "ax.set_ylabel('Density')\n",
                "ax.set_title('Distribution of Consumption Growth')\n",
                "ax.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SMM Setup\n",
                "\n",
                "For SMM, we need:\n",
                "1. **Target moments** from the data\n",
                "2. **Simulation function** that generates data given parameters\n",
                "3. **Moment function** that computes moments from simulated data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target moments from data\n",
                "# We'll match: mean, variance, and first-order autocorrelation\n",
                "data_mean = c_growth.mean()\n",
                "data_var = c_growth.var()\n",
                "data_autocorr = np.corrcoef(c_growth[1:], c_growth[:-1])[0, 1]\n",
                "\n",
                "data_moments = np.array([data_mean, data_var, data_autocorr])\n",
                "\n",
                "print(\"Target moments from data:\")\n",
                "print(f\"  Mean:            {data_mean:.6f}\")\n",
                "print(f\"  Variance:        {data_var:.6f}\")\n",
                "print(f\"  Autocorrelation: {data_autocorr:.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def simulate_ar1_measurement_error(theta, shocks):\n",
                "    \"\"\"\n",
                "    Simulate AR(1) process with measurement error.\n",
                "    \n",
                "    Model:\n",
                "        y*_t = mu + rho * (y*_{t-1} - mu) + sigma_eta * eta_t\n",
                "        y_t = y*_t + sigma_eps * eps_t\n",
                "    \n",
                "    Args:\n",
                "        theta: [mu, rho, sigma_eta, sigma_eps]\n",
                "        shocks: Array of shape (n_sim, T, 2) - [eta, eps] shocks\n",
                "    \n",
                "    Returns:\n",
                "        Simulated observed series of shape (n_sim, T)\n",
                "    \"\"\"\n",
                "    mu, rho, sigma_eta, sigma_eps = theta\n",
                "    \n",
                "    # Ensure positive std devs\n",
                "    sigma_eta = max(sigma_eta, 1e-6)\n",
                "    sigma_eps = max(sigma_eps, 1e-6)\n",
                "    rho = np.clip(rho, -0.999, 0.999)\n",
                "    \n",
                "    n_sim, T, _ = shocks.shape\n",
                "    \n",
                "    # Initialize latent process\n",
                "    y_star = np.zeros((n_sim, T))\n",
                "    y_star[:, 0] = mu + sigma_eta * shocks[:, 0, 0] / np.sqrt(1 - rho**2)\n",
                "    \n",
                "    # Simulate AR(1)\n",
                "    for t in range(1, T):\n",
                "        y_star[:, t] = mu + rho * (y_star[:, t-1] - mu) + sigma_eta * shocks[:, t, 0]\n",
                "    \n",
                "    # Add measurement error\n",
                "    y_obs = y_star + sigma_eps * shocks[:, :, 1]\n",
                "    \n",
                "    return y_obs\n",
                "\n",
                "\n",
                "def compute_moments_ar1(sim_data):\n",
                "    \"\"\"\n",
                "    Compute moments from simulated data.\n",
                "    \n",
                "    Args:\n",
                "        sim_data: Simulated series of shape (n_sim, T)\n",
                "    \n",
                "    Returns:\n",
                "        Moments of shape (n_sim, 3): [mean, variance, autocorr]\n",
                "    \"\"\"\n",
                "    n_sim, T = sim_data.shape\n",
                "    \n",
                "    # Mean\n",
                "    means = sim_data.mean(axis=1)\n",
                "    \n",
                "    # Variance\n",
                "    variances = sim_data.var(axis=1)\n",
                "    \n",
                "    # Autocorrelation\n",
                "    autocorrs = np.zeros(n_sim)\n",
                "    for i in range(n_sim):\n",
                "        if variances[i] > 1e-10:\n",
                "            autocorrs[i] = np.corrcoef(sim_data[i, 1:], sim_data[i, :-1])[0, 1]\n",
                "        else:\n",
                "            autocorrs[i] = 0.0\n",
                "    \n",
                "    return np.column_stack([means, variances, autocorrs])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the simulation\n",
                "T = len(c_growth)\n",
                "n_sim_test = 100\n",
                "\n",
                "np.random.seed(42)\n",
                "test_shocks = np.random.randn(n_sim_test, T, 2)\n",
                "\n",
                "# Test with reasonable parameters\n",
                "test_theta = [1.008, 0.3, 0.01, 0.005]  # mu, rho, sigma_eta, sigma_eps\n",
                "test_sim = simulate_ar1_measurement_error(test_theta, test_shocks)\n",
                "test_moments = compute_moments_ar1(test_sim)\n",
                "\n",
                "print(\"Test simulation:\")\n",
                "print(f\"  Simulated mean:     {test_moments[:, 0].mean():.6f} (target: {data_mean:.6f})\")\n",
                "print(f\"  Simulated variance: {test_moments[:, 1].mean():.6f} (target: {data_var:.6f})\")\n",
                "print(f\"  Simulated autocorr: {test_moments[:, 2].mean():.6f} (target: {data_autocorr:.6f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SMM estimation\n",
                "# Note: We need wrapper functions for smm_estimate\n",
                "\n",
                "def sim_func_wrapper(theta, shocks):\n",
                "    \"\"\"Wrapper for simulation function.\"\"\"\n",
                "    # Reshape shocks from (n_sim, T*2) to (n_sim, T, 2)\n",
                "    n_sim = shocks.shape[0]\n",
                "    T_local = shocks.shape[1] // 2\n",
                "    shocks_reshaped = shocks.reshape(n_sim, T_local, 2)\n",
                "    return simulate_ar1_measurement_error(theta, shocks_reshaped)\n",
                "\n",
                "def moment_func_wrapper(sim_data):\n",
                "    \"\"\"Wrapper for moment function.\"\"\"\n",
                "    return compute_moments_ar1(sim_data)\n",
                "\n",
                "# Run SMM\n",
                "print(\"Running SMM estimation...\")\n",
                "result_smm = smm_estimate(\n",
                "    sim_func=sim_func_wrapper,\n",
                "    moment_func=moment_func_wrapper,\n",
                "    data_moments=data_moments,\n",
                "    bounds=[\n",
                "        (0.99, 1.02),   # mu (mean consumption growth)\n",
                "        (-0.5, 0.9),    # rho (persistence)\n",
                "        (0.001, 0.05),  # sigma_eta (permanent shock std)\n",
                "        (0.001, 0.05),  # sigma_eps (measurement error std)\n",
                "    ],\n",
                "    n_sim=500,\n",
                "    shock_dim=T * 2,  # T periods × 2 shocks per period\n",
                "    seed=42,\n",
                "    weighting=\"optimal\",\n",
                "    n_global=100,\n",
                ")\n",
                "\n",
                "print(result_smm)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display results\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"SMM ESTIMATION RESULTS: AR(1) with Measurement Error\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "ci_lower_smm, ci_upper_smm = confidence_interval(result_smm.theta, result_smm.se)\n",
                "\n",
                "print(table_estimates(\n",
                "    theta=result_smm.theta,\n",
                "    se=result_smm.se,\n",
                "    param_names=[\"μ (mean)\", \"ρ (persistence)\", \"σ_η (perm shock)\", \"σ_ε (meas error)\"],\n",
                "    ci_lower=ci_lower_smm,\n",
                "    ci_upper=ci_upper_smm,\n",
                "))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check moment fit\n",
                "print(\"\\nMoment Fit:\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"{'Moment':<20} {'Data':>12} {'Model':>12} {'Diff':>12}\")\n",
                "print(\"-\" * 50)\n",
                "moment_names = ['Mean', 'Variance', 'Autocorrelation']\n",
                "for i, name in enumerate(moment_names):\n",
                "    diff = result_smm.sim_moments[i] - data_moments[i]\n",
                "    print(f\"{name:<20} {data_moments[i]:>12.6f} {result_smm.sim_moments[i]:>12.6f} {diff:>12.6f}\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize moment fit\n",
                "fig = plot_moment_comparison(\n",
                "    data_moments=data_moments,\n",
                "    model_moments=result_smm.sim_moments,\n",
                "    moment_names=moment_names,\n",
                ")\n",
                "plt.suptitle(\"SMM Moment Fit: AR(1) with Measurement Error\", y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpretation\n",
                "\n",
                "The estimated parameters tell us about consumption dynamics:\n",
                "\n",
                "- **μ ≈ 1.008**: Average quarterly consumption growth of ~0.8%\n",
                "- **ρ**: Persistence of consumption shocks (how much past shocks affect current consumption)\n",
                "- **σ_η**: Volatility of permanent consumption shocks\n",
                "- **σ_ε**: Measurement error in consumption data\n",
                "\n",
                "**Economic implications:**\n",
                "- Low ρ suggests consumption shocks are not very persistent\n",
                "- The ratio σ_η/σ_ε tells us about signal-to-noise in the data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparing Simulated vs Actual Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate data at estimated parameters\n",
                "np.random.seed(123)\n",
                "final_shocks = np.random.randn(1000, T, 2)\n",
                "sim_at_estimate = simulate_ar1_measurement_error(result_smm.theta, final_shocks)\n",
                "\n",
                "# Plot comparison\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "# Distribution comparison\n",
                "ax = axes[0]\n",
                "ax.hist(c_growth, bins=50, density=True, alpha=0.6, label='Data', edgecolor='black')\n",
                "ax.hist(sim_at_estimate.flatten(), bins=50, density=True, alpha=0.6, label='Simulated', edgecolor='black')\n",
                "ax.set_xlabel('Consumption Growth')\n",
                "ax.set_ylabel('Density')\n",
                "ax.set_title('Distribution: Data vs Simulated')\n",
                "ax.legend()\n",
                "\n",
                "# Autocorrelation comparison\n",
                "ax = axes[1]\n",
                "max_lag = 10\n",
                "data_acf = [np.corrcoef(c_growth[lag:], c_growth[:-lag])[0,1] if lag > 0 else 1.0 for lag in range(max_lag+1)]\n",
                "sim_acf = []\n",
                "for lag in range(max_lag+1):\n",
                "    if lag == 0:\n",
                "        sim_acf.append(1.0)\n",
                "    else:\n",
                "        acfs = [np.corrcoef(sim_at_estimate[i, lag:], sim_at_estimate[i, :-lag])[0,1] \n",
                "                for i in range(100)]\n",
                "        sim_acf.append(np.mean(acfs))\n",
                "\n",
                "ax.bar(np.arange(max_lag+1) - 0.15, data_acf, width=0.3, label='Data', alpha=0.7)\n",
                "ax.bar(np.arange(max_lag+1) + 0.15, sim_acf, width=0.3, label='Simulated', alpha=0.7)\n",
                "ax.set_xlabel('Lag')\n",
                "ax.set_ylabel('Autocorrelation')\n",
                "ax.set_title('Autocorrelation Function')\n",
                "ax.legend()\n",
                "ax.set_xticks(range(max_lag+1))\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Summary\n",
                "\n",
                "## What We Covered\n",
                "\n",
                "### Part 1: GMM with Labor Supply Data\n",
                "- Loaded and explored the Mroz (1987) PSID dataset\n",
                "- Identified the endogeneity problem in labor supply estimation\n",
                "- Used husband's characteristics as instruments\n",
                "- Estimated wage elasticity of labor supply via GMM\n",
                "- Tested overidentifying restrictions with J-test\n",
                "\n",
                "### Part 2: SMM for Income Dynamics\n",
                "- Modeled consumption as AR(1) with measurement error\n",
                "- Defined simulation and moment functions\n",
                "- Estimated parameters by matching mean, variance, and autocorrelation\n",
                "- Validated model fit by comparing simulated vs actual data\n",
                "\n",
                "## Key Takeaways\n",
                "\n",
                "1. **GMM is powerful for IV estimation** with real microdata\n",
                "2. **SMM is essential** when analytical moments are unavailable\n",
                "3. **Always check instrument validity** (first stage, J-test)\n",
                "4. **Moment selection matters** - choose informative moments\n",
                "5. **Bootstrap** (see Tutorial 4) provides robust inference for complex models\n",
                "\n",
                "## Exercises\n",
                "\n",
                "1. **Labor supply**: Try different instruments (e.g., husband's wage). Does the J-test still pass?\n",
                "2. **Income dynamics**: Add higher-order autocorrelations as moments. Does estimation improve?\n",
                "3. **Subsample analysis**: Estimate labor supply separately for women with/without children.\n",
                "4. **Model comparison**: Compare AR(1) vs AR(2) for consumption dynamics using SMM.\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "- See **Tutorial 6** for advanced structural models (Euler equations, dynamic discrete choice)\n",
                "- Explore the `asset_pricing` dataset for CCAPM estimation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise starter: Labor supply by presence of young children\n",
                "print(\"Exercise: Labor supply by presence of young children\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for has_kids, label in [(0, 'No young kids'), (1, 'Has young kids')]:\n",
                "    # Filter data\n",
                "    mask = labor_data.data['youngkids'] > 0 if has_kids else labor_data.data['youngkids'] == 0\n",
                "    \n",
                "    subset_data = {k: v[mask] for k, v in labor_data.data.items()}\n",
                "    n_subset = int(mask.sum())\n",
                "    \n",
                "    if n_subset < 50:\n",
                "        print(f\"\\n{label}: Too few observations ({n_subset})\")\n",
                "        continue\n",
                "    \n",
                "    result_subset = gmm_estimate(\n",
                "        data=subset_data,\n",
                "        moment_func=labor_supply_moments,\n",
                "        bounds=[(0, 10), (-2, 2), (-0.5, 0.5), (-0.5, 0.5), (-0.1, 0.1)],\n",
                "        k=5,\n",
                "        weighting=\"optimal\",\n",
                "        n_global=100,\n",
                "        seed=42,\n",
                "    )\n",
                "    \n",
                "    print(f\"\\n{label} (n={n_subset}):\")\n",
                "    print(f\"  γ (wage elasticity) = {result_subset.theta[1]:.4f} (SE: {result_subset.se[1]:.4f})\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}