{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tutorial 1: GMM Basics\n",
                "\n",
                "This tutorial introduces the **Generalized Method of Moments (GMM)** and demonstrates how to use `momentest` for GMM estimation.\n",
                "\n",
                "## What You'll Learn\n",
                "\n",
                "1. What GMM is and when to use it\n",
                "2. How to define moment conditions\n",
                "3. How to estimate parameters using `gmm_estimate()`\n",
                "4. How to interpret results and diagnostics\n",
                "\n",
                "## Prerequisites\n",
                "\n",
                "- Basic knowledge of econometrics (OLS, IV)\n",
                "- Familiarity with Python and NumPy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Import momentest\n",
                "from momentest import (\n",
                "    gmm_estimate,\n",
                "    linear_iv,\n",
                "    j_test,\n",
                "    table_estimates,\n",
                "    confidence_interval,\n",
                "    plot_moment_comparison,\n",
                ")\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. What is GMM?\n",
                "\n",
                "**Generalized Method of Moments (GMM)** is an estimation method based on **moment conditions** - equations that should hold at the true parameter values.\n",
                "\n",
                "### The Key Idea\n",
                "\n",
                "Suppose we have a model with parameters $\\theta$ and data $\\{z_i\\}_{i=1}^n$. We define **moment conditions**:\n",
                "\n",
                "$$E[g(z_i, \\theta_0)] = 0$$\n",
                "\n",
                "where $\\theta_0$ is the true parameter value. GMM finds $\\hat{\\theta}$ that makes the sample moments as close to zero as possible:\n",
                "\n",
                "$$\\hat{\\theta} = \\arg\\min_\\theta \\bar{g}(\\theta)' W \\bar{g}(\\theta)$$\n",
                "\n",
                "where $\\bar{g}(\\theta) = \\frac{1}{n}\\sum_{i=1}^n g(z_i, \\theta)$ and $W$ is a weighting matrix.\n",
                "\n",
                "### When to Use GMM\n",
                "\n",
                "- **Instrumental Variables (IV)**: When you have endogenous regressors\n",
                "- **Overidentification**: When you have more moment conditions than parameters\n",
                "- **Robust estimation**: When you want to avoid distributional assumptions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Example: Linear IV Model\n",
                "\n",
                "Let's start with the classic **linear IV model**:\n",
                "\n",
                "$$Y = \\beta_0 + \\beta_1 X + \\varepsilon$$\n",
                "\n",
                "where $X$ is **endogenous** (correlated with $\\varepsilon$). We have an instrument $Z$ that:\n",
                "1. **Relevance**: $Cov(Z, X) \\neq 0$\n",
                "2. **Exclusion**: $Cov(Z, \\varepsilon) = 0$\n",
                "\n",
                "### Generate Data\n",
                "\n",
                "We'll use the built-in `linear_iv` DGP (Data Generating Process):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate data from linear IV model\n",
                "dgp = linear_iv(n=1000, seed=42, beta0=1.0, beta1=2.0, rho=0.5)\n",
                "\n",
                "# Print info about the DGP\n",
                "dgp.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract data\n",
                "Y = dgp.data['Y']\n",
                "X = dgp.data['X']\n",
                "Z = dgp.data['Z']\n",
                "\n",
                "print(f\"True parameters: β₀ = {dgp.true_theta[0]}, β₁ = {dgp.true_theta[1]}\")\n",
                "print(f\"Sample size: n = {dgp.n}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Why OLS Fails\n",
                "\n",
                "Let's first see what happens with OLS:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OLS estimation (biased due to endogeneity)\n",
                "X_ols = np.column_stack([np.ones(len(Y)), X])\n",
                "beta_ols = np.linalg.lstsq(X_ols, Y, rcond=None)[0]\n",
                "\n",
                "print(f\"OLS estimates: β₀ = {beta_ols[0]:.4f}, β₁ = {beta_ols[1]:.4f}\")\n",
                "print(f\"True values:   β₀ = {dgp.true_theta[0]:.4f}, β₁ = {dgp.true_theta[1]:.4f}\")\n",
                "print(f\"\\nOLS is BIASED because X is endogenous (correlated with ε)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. GMM Moment Conditions\n",
                "\n",
                "For the linear IV model, the moment conditions are:\n",
                "\n",
                "1. $E[\\varepsilon] = 0$ → $E[Y - \\beta_0 - \\beta_1 X] = 0$\n",
                "2. $E[Z \\cdot \\varepsilon] = 0$ → $E[Z(Y - \\beta_0 - \\beta_1 X)] = 0$\n",
                "\n",
                "Let's define the moment function:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def moment_func(data, theta):\n",
                "    \"\"\"\n",
                "    GMM moment conditions for linear IV.\n",
                "    \n",
                "    Args:\n",
                "        data: Dictionary with 'Y', 'X', 'Z' arrays\n",
                "        theta: [beta0, beta1] parameters\n",
                "    \n",
                "    Returns:\n",
                "        Moment conditions of shape (n, k) where k=2\n",
                "    \"\"\"\n",
                "    beta0, beta1 = theta\n",
                "    \n",
                "    # Residual\n",
                "    residual = data['Y'] - beta0 - beta1 * data['X']\n",
                "    \n",
                "    # Moment conditions\n",
                "    moments = np.column_stack([\n",
                "        residual,              # E[ε] = 0\n",
                "        residual * data['Z'], # E[Zε] = 0 (exclusion restriction)\n",
                "    ])\n",
                "    \n",
                "    return moments"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. GMM Estimation with momentest\n",
                "\n",
                "Now let's estimate using `gmm_estimate()`. This is the simple, high-level API:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GMM estimation - just a few lines!\n",
                "result = gmm_estimate(\n",
                "    data=dgp.data,           # Pass the data dictionary\n",
                "    moment_func=moment_func, # Our moment function\n",
                "    bounds=[(-10, 10), (-10, 10)],  # Parameter bounds\n",
                "    k=2,                     # Number of moment conditions\n",
                "    weighting=\"optimal\",    # Two-step optimal weighting\n",
                ")\n",
                "\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare estimates\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "print(f\"{'Method':<15} {'β₀':>12} {'β₁':>12}\")\n",
                "print(\"-\"*40)\n",
                "print(f\"{'True':<15} {dgp.true_theta[0]:>12.4f} {dgp.true_theta[1]:>12.4f}\")\n",
                "print(f\"{'OLS (biased)':<15} {beta_ols[0]:>12.4f} {beta_ols[1]:>12.4f}\")\n",
                "print(f\"{'GMM':<15} {result.theta[0]:>12.4f} {result.theta[1]:>12.4f}\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nGMM recovers the true parameters! OLS is biased upward.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Understanding the Results\n",
                "\n",
                "### Parameter Estimates and Standard Errors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Formatted table of estimates\n",
                "ci_lower, ci_upper = confidence_interval(result.theta, result.se)\n",
                "\n",
                "print(table_estimates(\n",
                "    theta=result.theta,\n",
                "    se=result.se,\n",
                "    param_names=[\"β₀ (intercept)\", \"β₁ (slope)\"],\n",
                "    ci_lower=ci_lower,\n",
                "    ci_upper=ci_upper,\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Moment Fit\n",
                "\n",
                "At the estimated parameters, the sample moments should be close to zero:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check moment fit\n",
                "print(f\"Sample moments at θ̂: {result.sample_moments}\")\n",
                "print(f\"\\nThese should be close to zero (the target).\")\n",
                "print(f\"Objective value: {result.objective:.2e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Identity vs Optimal Weighting\n",
                "\n",
                "GMM allows different weighting matrices $W$:\n",
                "\n",
                "- **Identity**: $W = I$ (simple, but not efficient)\n",
                "- **Optimal**: $W = S^{-1}$ where $S$ is the moment covariance (efficient)\n",
                "\n",
                "Let's compare:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identity weighting (one-step)\n",
                "result_identity = gmm_estimate(\n",
                "    data=dgp.data,\n",
                "    moment_func=moment_func,\n",
                "    bounds=[(-10, 10), (-10, 10)],\n",
                "    k=2,\n",
                "    weighting=\"identity\",\n",
                ")\n",
                "\n",
                "# Optimal weighting (two-step)\n",
                "result_optimal = gmm_estimate(\n",
                "    data=dgp.data,\n",
                "    moment_func=moment_func,\n",
                "    bounds=[(-10, 10), (-10, 10)],\n",
                "    k=2,\n",
                "    weighting=\"optimal\",\n",
                ")\n",
                "\n",
                "print(f\"{'Weighting':<15} {'β₀':>10} {'β₁':>10} {'SE(β₁)':>10}\")\n",
                "print(\"-\"*50)\n",
                "print(f\"{'Identity':<15} {result_identity.theta[0]:>10.4f} {result_identity.theta[1]:>10.4f} {result_identity.se[1]:>10.4f}\")\n",
                "print(f\"{'Optimal':<15} {result_optimal.theta[0]:>10.4f} {result_optimal.theta[1]:>10.4f} {result_optimal.se[1]:>10.4f}\")\n",
                "print(f\"{'True':<15} {dgp.true_theta[0]:>10.4f} {dgp.true_theta[1]:>10.4f} {'-':>10}\")\n",
                "print(\"\\nOptimal weighting is asymptotically efficient (lower SE).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Overidentification and the J-Test\n",
                "\n",
                "When we have more moments than parameters ($k > p$), the model is **overidentified**. We can test whether all moment conditions hold using the **J-test** (Hansen-Sargan test).\n",
                "\n",
                "Let's add another instrument to create an overidentified model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add a second instrument (Z squared, for illustration)\n",
                "dgp.data['Z2'] = dgp.data['Z']**2\n",
                "\n",
                "def moment_func_overid(data, theta):\n",
                "    \"\"\"\n",
                "    Overidentified GMM: 3 moments, 2 parameters.\n",
                "    \"\"\"\n",
                "    beta0, beta1 = theta\n",
                "    residual = data['Y'] - beta0 - beta1 * data['X']\n",
                "    \n",
                "    moments = np.column_stack([\n",
                "        residual,               # E[ε] = 0\n",
                "        residual * data['Z'],   # E[Zε] = 0\n",
                "        residual * data['Z2'],  # E[Z²ε] = 0 (additional moment)\n",
                "    ])\n",
                "    \n",
                "    return moments\n",
                "\n",
                "# Estimate overidentified model\n",
                "result_overid = gmm_estimate(\n",
                "    data=dgp.data,\n",
                "    moment_func=moment_func_overid,\n",
                "    bounds=[(-10, 10), (-10, 10)],\n",
                "    k=3,  # Now 3 moments\n",
                "    weighting=\"optimal\",\n",
                ")\n",
                "\n",
                "print(f\"Overidentified estimates: β₀ = {result_overid.theta[0]:.4f}, β₁ = {result_overid.theta[1]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# J-test for overidentifying restrictions\n",
                "j_result = j_test(\n",
                "    objective=result_overid.objective,\n",
                "    n=dgp.n,\n",
                "    k=3,  # 3 moments\n",
                "    p=2,  # 2 parameters\n",
                ")\n",
                "\n",
                "print(j_result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Interpreting the J-Test\n",
                "\n",
                "- **H₀**: All moment conditions are valid\n",
                "- **H₁**: At least one moment condition is invalid\n",
                "\n",
                "If we **fail to reject** H₀ (high p-value), the instruments are likely valid.\n",
                "If we **reject** H₀ (low p-value), at least one instrument may be invalid."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot moment comparison\n",
                "fig = plot_moment_comparison(\n",
                "    data_moments=np.zeros(2),  # Target is zero for GMM\n",
                "    model_moments=result.sample_moments,\n",
                "    moment_names=[\"E[ε]\", \"E[Zε]\"],\n",
                ")\n",
                "plt.suptitle(\"GMM Moment Fit\", y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Exercises\n",
                "\n",
                "Try these exercises to deepen your understanding:\n",
                "\n",
                "### Exercise 1: Change the Endogeneity\n",
                "Regenerate data with different `rho` values (0.1, 0.3, 0.7). How does OLS bias change? Does GMM still work?\n",
                "\n",
                "### Exercise 2: Weak Instruments\n",
                "Modify the DGP to have a weak instrument (low correlation between Z and X). What happens to GMM estimates?\n",
                "\n",
                "### Exercise 3: Invalid Instrument\n",
                "Add an instrument that violates the exclusion restriction. Does the J-test detect it?\n",
                "\n",
                "### Exercise 4: Real Data\n",
                "Try the `load_labor_supply()` dataset for a real-world IV example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1 starter code\n",
                "for rho in [0.1, 0.3, 0.5, 0.7]:\n",
                "    dgp_ex = linear_iv(n=1000, seed=42, rho=rho)\n",
                "    \n",
                "    # OLS\n",
                "    X_ols = np.column_stack([np.ones(dgp_ex.n), dgp_ex.data['X']])\n",
                "    beta_ols = np.linalg.lstsq(X_ols, dgp_ex.data['Y'], rcond=None)[0]\n",
                "    \n",
                "    # GMM\n",
                "    result_ex = gmm_estimate(\n",
                "        data=dgp_ex.data,\n",
                "        moment_func=moment_func,\n",
                "        bounds=[(-10, 10), (-10, 10)],\n",
                "        k=2,\n",
                "        weighting=\"optimal\",\n",
                "    )\n",
                "    \n",
                "    print(f\"ρ={rho}: OLS β₁={beta_ols[1]:.3f}, GMM β₁={result_ex.theta[1]:.3f}, True β₁=2.0\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this tutorial, you learned:\n",
                "\n",
                "1. **GMM basics**: Estimation based on moment conditions $E[g(z, \\theta)] = 0$\n",
                "2. **Moment functions**: How to define `moment_func(data, theta)` returning $(n, k)$ array\n",
                "3. **Simple API**: `gmm_estimate()` handles optimization, weighting, and inference\n",
                "4. **Weighting**: Identity vs optimal (two-step efficient)\n",
                "5. **J-test**: Testing overidentifying restrictions when $k > p$\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "- GMM is powerful for IV estimation and robust inference\n",
                "- The moment function is the key input - it encodes your economic model\n",
                "- Optimal weighting gives efficient estimates\n",
                "- The J-test helps validate your instruments\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- **Tutorial 2**: SMM basics - when you need to simulate moments\n",
                "- **Tutorial 3**: Optimal weighting in depth\n",
                "- **Tutorial 4**: Bootstrap inference"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}